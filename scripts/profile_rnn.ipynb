{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pypose as pp\n",
    "import numpy as np\n",
    "from utile import parse_param\n",
    "from nn_utile import AUVTraj, AUVStep, AUVRNNDeltaV\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_device(gpu=False, unit=0):\n",
    "    use_cuda = False\n",
    "    if gpu:\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        if not use_cuda:\n",
    "            warnings.warn(\"Asked for GPU but torch couldn't find a Cuda capable device\")\n",
    "    return torch.device(f\"cuda:{unit}\" if use_cuda else \"cpu\")\n",
    "\n",
    "'''\n",
    "Runs a given RNN Model with a given input state and action sequence.\n",
    "'''\n",
    "def run(model, state, X):\n",
    "    # TODO: disable all log, just keep the trajectory.\n",
    "    traj = model(state, X)\n",
    "    return traj\n",
    "\n",
    "'''\n",
    "Load a RNN Model given a checkpoint file.\n",
    "'''\n",
    "def load_model(model, ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt)\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(params, device):\n",
    "    model = AUVTraj(params).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../train_log/2023.04.24-11:25:38/\"\n",
    "param_file = os.path.join(path, \"parameters.yaml\")\n",
    "param = parse_param(param_file)\n",
    "ckpt_path = os.path.join(path, \"ckpt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device(True)\n",
    "\n",
    "state = torch.zeros(size=(20, 1, 13)).to(device)\n",
    "state[..., 6] = 1.\n",
    "seq = torch.zeros(size=(20, 10, 6)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-03 11:43:16 12795:12795 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-03 11:43:20 12795:12795 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-03 11:43:20 12795:12795 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = create_model(param, device)\n",
    "model = load_model(model, ckpt_path)\n",
    "# Warm-up\n",
    "traj = model(state, seq)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(state, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        cudaMemcpyAsync        72.37%        1.782s        72.37%        1.782s       7.616ms     389.000us         1.18%     389.000us       1.662us           0 b           0 b           0 b           0 b           234  \n",
      "                                            aten::alias         2.50%      61.536ms         2.50%      61.536ms     603.294us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           102  \n",
      "                                            aten::slice         2.30%      56.651ms         2.33%      57.372ms     210.926us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           272  \n",
      "                                            aten::copy_         2.22%      54.638ms         3.72%      91.657ms       1.410ms     840.000us         2.55%     877.000us      13.492us           0 b           0 b           0 b           0 b            65  \n",
      "                                       cudaLaunchKernel         1.54%      37.961ms         1.54%      37.961ms      19.201us       2.920ms         8.87%       2.920ms       1.477us           0 b           0 b           0 b           0 b          1977  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.462s\n",
      "Self CUDA time total: 32.923ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(prof.key_averages(group_by_stack_n=5))\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like most of the memcpy happens in pypose operations. Need to identify which one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:433: UserWarning: use_cuda is deprecated, use activities argument instead\n",
      "  warn(\"use_cuda is deprecated, use activities argument instead\")\n",
      "STAGE:2023-05-03 11:43:32 12795:12795 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-03 11:43:32 12795:12795 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-03 11:43:32 12795:12795 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        cudaMemcpyAsync        83.93%     226.874ms        83.93%     226.874ms       9.864ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            23  \n",
      "                                  cudaDeviceSynchronize         1.84%       4.969ms         1.84%       4.969ms       4.969ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       cudaLaunchKernel         1.26%       3.409ms         1.26%       3.409ms      17.131us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           199  \n",
      "                                        model_inference         1.24%       3.350ms        98.16%     265.349ms     265.349ms       0.000us         0.00%       3.119ms       3.119ms           0 b           0 b           0 b     -30.00 Kb             1  \n",
      "                                            aten::alias         0.98%       2.652ms         0.98%       2.652ms     265.200us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            10  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 270.318ms\n",
      "Self CUDA time total: 3.119ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = AUVStep().to(device)\n",
    "h = None\n",
    "p = state[..., :7]\n",
    "v = state[..., 7:]\n",
    "\n",
    "x = pp.SE3(p).to(device)\n",
    "\n",
    "# Warm-up\n",
    "x, v, dv, h = step(x, v, seq[:, 0:1], h)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        step(x, v, seq[:, 0:1], h)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        31.25%       5.009ms        99.87%      16.009ms      16.009ms       0.000us         0.00%     580.000us     580.000us           0 b           0 b       4.00 Kb     -22.00 Kb             1  \n",
      "                                               aten::mm        11.96%       1.917ms        12.48%       2.001ms     667.000us      99.000us        17.07%      99.000us      33.000us           0 b           0 b       5.50 Kb       5.50 Kb             3  \n",
      "                                                aten::t        10.21%       1.636ms        10.36%       1.661ms     553.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                aten::native_batch_norm         7.57%       1.214ms         8.50%       1.363ms     681.500us     130.000us        22.41%     130.000us      65.000us           0 b           0 b       7.00 Kb           0 b             2  \n",
      "                                       aten::leaky_relu         7.21%       1.156ms         7.48%       1.199ms     599.500us      22.000us         3.79%      22.000us      11.000us           0 b           0 b       5.00 Kb       5.00 Kb             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 16.030ms\n",
      "Self CUDA time total: 580.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-03 11:43:34 12795:12795 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-03 11:43:34 12795:12795 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-03 11:43:34 12795:12795 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "dv = AUVRNNDeltaV().to(device)\n",
    "step = AUVStep().to(device)\n",
    "h = None\n",
    "p = state[..., :7]\n",
    "v = state[..., 7:]\n",
    "\n",
    "x = pp.SE3(p).to(device)\n",
    "# Warm-up\n",
    "res, h = dv(x, v, seq[:, 0:1], h)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        res, h = dv(x, v, seq[:, 0:1], h)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-03 11:43:35 12795:12795 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-03 11:43:36 12795:12795 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-03 11:43:36 12795:12795 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        cudaMemcpyAsync        87.15%     229.085ms        87.15%     229.085ms       9.960ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            23  \n",
      "                                  cudaDeviceSynchronize         4.74%      12.456ms         4.74%      12.456ms      12.456ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                                se3_Exp         2.39%       6.274ms        95.11%     250.027ms     250.027ms       0.000us         0.00%       2.266ms       2.266ms           0 b           0 b       1.00 Kb     -18.50 Kb             1  \n",
      "                                       cudaLaunchKernel         1.26%       3.310ms         1.26%       3.310ms      23.310us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           142  \n",
      "                                          aten::nonzero         0.98%       2.587ms        89.25%     234.615ms      10.201ms       1.338ms        59.05%       1.338ms      58.174us           0 b           0 b       7.00 Kb           0 b            23  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 262.875ms\n",
      "Self CUDA time total: 2.266ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"exp\"):\n",
    "        tg = pp.se3(v)\n",
    "        t = tg.Exp()\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=2).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't disable Kineto profiler when it's not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m profile(with_stack\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, profile_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, use_cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m      2\u001b[0m     \u001b[39mwith\u001b[39;00m record_function(\u001b[39m\"\u001b[39m\u001b[39madj\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m         x\u001b[39m.\u001b[39mAdj(v)\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:505\u001b[0m, in \u001b[0;36mprofile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:513\u001b[0m, in \u001b[0;36mprofile.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transit_action(ProfilerAction\u001b[39m.\u001b[39;49mNONE, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_action)\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord_steps:\n\u001b[1;32m    515\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_rec_fn \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mProfilerStep#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_num))\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:549\u001b[0m, in \u001b[0;36mprofile._transit_action\u001b[0;34m(self, prev_action, current_action)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mif\u001b[39;00m action_list:\n\u001b[1;32m    548\u001b[0m     \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m action_list:\n\u001b[0;32m--> 549\u001b[0m         action()\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:115\u001b[0m, in \u001b[0;36m_KinetoProfile.prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39mprofile(\n\u001b[1;32m    105\u001b[0m         use_cuda\u001b[39m=\u001b[39m(ProfilerActivity\u001b[39m.\u001b[39mCUDA \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities),\n\u001b[1;32m    106\u001b[0m         use_cpu\u001b[39m=\u001b[39m(ProfilerActivity\u001b[39m.\u001b[39mCPU \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m         experimental_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_config,\n\u001b[1;32m    114\u001b[0m     )\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_prepare_trace()\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/autograd/profiler.py:220\u001b[0m, in \u001b[0;36mprofile._prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     _prepare_profiler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkineto_activities)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't disable Kineto profiler when it's not running"
     ]
    }
   ],
   "source": [
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"adj\"):\n",
    "        x.Adj(v)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=2).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to implement two version of skew matrix and run them for multiple time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pypose implementation\n",
    "def vec2skew(input:torch.Tensor) -> torch.Tensor:\n",
    "    v = input.tensor() if hasattr(input, 'ltype') else input\n",
    "    assert v.shape[-1] == 3, \"Last dim should be 3\"\n",
    "    skew = torch.zeros(v.shape + (3,), device=v.device, dtype=v.dtype)\n",
    "    skew[..., 0, 1], skew[..., 0, 2] = -v[..., 2],   v[..., 1]\n",
    "    skew[..., 1, 0], skew[..., 1, 2] =  v[..., 2],  -v[..., 0]\n",
    "    skew[..., 2, 0], skew[..., 2, 1] = -v[..., 1],   v[..., 0]\n",
    "    return skew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skew_pad = torch.zeros((3, 3), requires_grad=True).to(device=device)\n",
    "\n",
    "def vec2skew2(input:torch.Tensor) -> torch.Tensor:\n",
    "    v = input.tensor() if hasattr(input, 'ltype') else input\n",
    "    assert v.shape[-1] == 3, \"Last dim should be 3\"\n",
    "    skew = skew_pad.expand(v.shape + (3,)).detach().clone()\n",
    "    skew[..., 0, 1] += -v[..., 2]\n",
    "    skew[..., 0, 2] +=  v[..., 1]\n",
    "    skew[..., 1, 0] +=  v[..., 2]\n",
    "    skew[..., 1, 2] += -v[..., 0]\n",
    "    skew[..., 2, 0] += -v[..., 1]\n",
    "    skew[..., 2, 1] +=  v[..., 0]\n",
    "    return skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't disable Kineto profiler when it's not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(device)\n\u001b[1;32m      2\u001b[0m vec \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m2000\u001b[39m, \u001b[39m3\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mwith\u001b[39;00m profile(with_stack\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, profile_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, use_cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m      5\u001b[0m     \u001b[39mwith\u001b[39;00m record_function(\u001b[39m\"\u001b[39m\u001b[39mskew\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:505\u001b[0m, in \u001b[0;36mprofile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:513\u001b[0m, in \u001b[0;36mprofile.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transit_action(ProfilerAction\u001b[39m.\u001b[39;49mNONE, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_action)\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord_steps:\n\u001b[1;32m    515\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_rec_fn \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mProfilerStep#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_num))\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:549\u001b[0m, in \u001b[0;36mprofile._transit_action\u001b[0;34m(self, prev_action, current_action)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mif\u001b[39;00m action_list:\n\u001b[1;32m    548\u001b[0m     \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m action_list:\n\u001b[0;32m--> 549\u001b[0m         action()\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:115\u001b[0m, in \u001b[0;36m_KinetoProfile.prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39mprofile(\n\u001b[1;32m    105\u001b[0m         use_cuda\u001b[39m=\u001b[39m(ProfilerActivity\u001b[39m.\u001b[39mCUDA \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities),\n\u001b[1;32m    106\u001b[0m         use_cpu\u001b[39m=\u001b[39m(ProfilerActivity\u001b[39m.\u001b[39mCPU \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m         experimental_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_config,\n\u001b[1;32m    114\u001b[0m     )\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_prepare_trace()\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/autograd/profiler.py:220\u001b[0m, in \u001b[0;36mprofile._prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     _prepare_profiler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkineto_activities)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't disable Kineto profiler when it's not running"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "vec = torch.rand((2000, 3)).to(device)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"skew\"):\n",
    "        for i in range(50):\n",
    "            vec2skew(vec)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't disable Kineto profiler when it's not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vec \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m2000\u001b[39m, \u001b[39m3\u001b[39m))\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m profile(with_stack\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, profile_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, use_cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m prof:\n\u001b[1;32m      4\u001b[0m     \u001b[39mwith\u001b[39;00m record_function(\u001b[39m\"\u001b[39m\u001b[39mskew\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:505\u001b[0m, in \u001b[0;36mprofile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:513\u001b[0m, in \u001b[0;36mprofile.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transit_action(ProfilerAction\u001b[39m.\u001b[39;49mNONE, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_action)\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord_steps:\n\u001b[1;32m    515\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_rec_fn \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39mrecord_function(\u001b[39m\"\u001b[39m\u001b[39mProfilerStep#\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_num))\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:549\u001b[0m, in \u001b[0;36mprofile._transit_action\u001b[0;34m(self, prev_action, current_action)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mif\u001b[39;00m action_list:\n\u001b[1;32m    548\u001b[0m     \u001b[39mfor\u001b[39;00m action \u001b[39min\u001b[39;00m action_list:\n\u001b[0;32m--> 549\u001b[0m         action()\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/profiler/profiler.py:115\u001b[0m, in \u001b[0;36m_KinetoProfile.prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39mprofile(\n\u001b[1;32m    105\u001b[0m         use_cuda\u001b[39m=\u001b[39m(ProfilerActivity\u001b[39m.\u001b[39mCUDA \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities),\n\u001b[1;32m    106\u001b[0m         use_cpu\u001b[39m=\u001b[39m(ProfilerActivity\u001b[39m.\u001b[39mCPU \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivities),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m         experimental_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_config,\n\u001b[1;32m    114\u001b[0m     )\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_prepare_trace()\n",
      "File \u001b[0;32m~/anaconda3/envs/pp_local/lib/python3.9/site-packages/torch/autograd/profiler.py:220\u001b[0m, in \u001b[0;36mprofile._prepare_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_trace\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentered \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     _prepare_profiler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkineto_activities)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't disable Kineto profiler when it's not running"
     ]
    }
   ],
   "source": [
    "vec = torch.rand((2000, 3)).to(device)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"skew\"):\n",
    "        for i in range(50):\n",
    "            vec2skew2(vec)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time_dict = {}\n",
    "time_dict[\"vec2skew\"] = 0.\n",
    "time_dict[\"theta\"] = 0.\n",
    "time_dict[\"I\"] = 0.\n",
    "time_dict[\"idx\"] = 0.\n",
    "time_dict[\"coef1_z\"] = 0.\n",
    "time_dict[\"coef1_l_cos\"] = 0.\n",
    "time_dict[\"coef1_l_div\"] = 0.\n",
    "time_dict[\"coef1_s_comp\"] = 0.\n",
    "time_dict[\"coef1\"] = 0.\n",
    "time_dict[\"coef2_z\"] = 0.\n",
    "time_dict[\"coef2_l_comp\"] = 0.\n",
    "time_dict[\"coef2_s_comp\"] = 0.\n",
    "time_dict[\"coef2\"] = 0.\n",
    "time_dict[\"res\"] = 0.\n",
    "time_dict[\"so3_jl\"] = 0.\n",
    "time_dict[\"t\"] = 0.\n",
    "time_dict[\"so3_Exp\"] = 0.\n",
    "time_dict[\"so3_theta\"] = 0.\n",
    "time_dict[\"so3_placeholder\"] = 0.\n",
    "time_dict[\"so3_idx\"] = 0.\n",
    "time_dict[\"so3_l_img_comp\"] = 0.\n",
    "time_dict[\"so3_l_real_comp\"] = 0.\n",
    "time_dict[\"so3_s_img_comp\"] = 0.\n",
    "time_dict[\"so3_s_real_comp\"] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2skew(input:torch.Tensor) -> torch.Tensor:\n",
    "    v = input.tensor() if hasattr(input, 'ltype') else input\n",
    "    assert v.shape[-1] == 3, \"Last dim should be 3\"\n",
    "    O = torch.zeros(v.shape[:-1], device=v.device, dtype=v.dtype, requires_grad=v.requires_grad)\n",
    "    return torch.stack([torch.stack([        O, -v[...,2],  v[...,1]], dim=-1),\n",
    "                        torch.stack([ v[...,2],         O, -v[...,0]], dim=-1),\n",
    "                        torch.stack([-v[...,1],  v[...,0],         O], dim=-1)], dim=-2)\n",
    "\n",
    "def so3_Jl(x:torch.Tensor):\n",
    "    ## Skew\n",
    "    start = time.perf_counter()\n",
    "    K = vec2skew(x)\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"vec2skew\"] += end-start\n",
    "\n",
    "    ## Theta\n",
    "    start = time.perf_counter()\n",
    "    theta = torch.linalg.norm(x, dim=-1, keepdim=True).unsqueeze(-1)\n",
    "    theta2 = theta**2\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"theta\"] += end-start\n",
    "\n",
    "    ## Eye\n",
    "    start = time.perf_counter()\n",
    "    I = torch.eye(3, device=x.device, dtype=x.dtype).expand(x.shape[:-1]+(3, 3))\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"I\"] += end - start\n",
    "\n",
    "    ## large angle idx\n",
    "    start = time.perf_counter()\n",
    "    idx = (theta > torch.finfo(theta.dtype).eps)\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"idx\"] += end-start\n",
    "\n",
    "    ## Coef 1 computation\n",
    "    start_coef = time.perf_counter()\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    coef1 = torch.zeros_like(theta, requires_grad=False)\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef1_z\"] += end-start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    c = (1-theta[idx].cos())\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef1_l_cos\"] += end-start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    coef1[idx] = c/theta2[idx]\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef1_l_div\"] += end-start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    coef1[~idx] = 0.5 - (1.0/24.0) * theta2[~idx]\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef1_s_comp\"] += end-start\n",
    "\n",
    "    end_coef = time.perf_counter()\n",
    "    time_dict[\"coef1\"] += end_coef-start_coef\n",
    "\n",
    "    start_coef = time.perf_counter()\n",
    "    start = time.perf_counter()\n",
    "    coef2 = torch.zeros_like(theta, requires_grad=False)\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef2_z\"] += end-start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    coef2[idx] = (theta[idx] - theta[idx].sin()) / (theta[idx] * theta2[idx])\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef2_l_comp\"] += end-start\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    coef2[~idx] = 1.0/6.0 - (1.0/120) * theta2[~idx]\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"coef2_s_comp\"] += end-start\n",
    "\n",
    "    end_coef = time.perf_counter()\n",
    "    time_dict[\"coef2\"] += end_coef-start_coef\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    res = (I + coef1 * K + coef2 * (K@K))\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"res\"] += end-start\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "class se3_Exp(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        start = time.perf_counter()\n",
    "        jl = so3_Jl(input[..., 3:])\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_jl\"] += end-start\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        t = (jl @ input[..., :3].unsqueeze(-1)).squeeze(-1)\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"t\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        r = so3_Exp.apply(input[..., 3:])\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_Exp\"] += end-start\n",
    "\n",
    "        return torch.cat([t, r], -1), time_dict\n",
    "\n",
    "class so3_Exp(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        start = time.perf_counter()\n",
    "        theta = torch.norm(input, 2, dim=-1, keepdim=True)\n",
    "        start = time.perf_counter()        \n",
    "        theta_half, theta2 = 0.5 * theta, theta * theta\n",
    "        theta4 = theta2 * theta2\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_theta\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        imag_factor = torch.zeros_like(theta, requires_grad=False)\n",
    "        real_factor = torch.zeros_like(theta, requires_grad=False)\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_placeholder\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        idx = (theta > torch.finfo(theta.dtype).eps)\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_idx\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        imag_factor[idx] = torch.sin(theta_half[idx]) / theta[idx]\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_l_img_comp\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        real_factor[idx] = torch.cos(theta_half[idx])\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_l_real_comp\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        imag_factor[~idx] = 0.5 - (1.0/48.0) * theta2[~idx] + (1.0/3840.0) * theta4[~idx]\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_s_img_comp\"] += end-start\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        real_factor[~idx] = 1.0 - (1.0/8.0) * theta2[~idx] + (1.0/384.0) * theta4[~idx]\n",
    "        end = time.perf_counter()\n",
    "        time_dict[\"so3_s_real_comp\"] += end-start\n",
    "\n",
    "        return torch.cat([input * imag_factor, real_factor], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "time_dict[\"vec2skew\"] = 0.\n",
    "time_dict[\"theta\"] = 0.\n",
    "time_dict[\"I\"] = 0.\n",
    "time_dict[\"idx\"] = 0.\n",
    "time_dict[\"coef1_z\"] = 0.\n",
    "time_dict[\"coef1_l_cos\"] = 0.\n",
    "time_dict[\"coef1_l_div\"] = 0.\n",
    "time_dict[\"coef1_s_comp\"] = 0.\n",
    "time_dict[\"coef1\"] = 0.\n",
    "time_dict[\"coef2_z\"] = 0.\n",
    "time_dict[\"coef2_l_comp\"] = 0.\n",
    "time_dict[\"coef2_s_comp\"] = 0.\n",
    "time_dict[\"coef2\"] = 0.\n",
    "time_dict[\"res\"] = 0.\n",
    "time_dict[\"so3_jl\"] = 0.\n",
    "time_dict[\"t\"] = 0.\n",
    "time_dict[\"so3_Exp\"] = 0.\n",
    "time_dict[\"so3_theta\"] = 0.\n",
    "time_dict[\"so3_placeholder\"] = 0.\n",
    "time_dict[\"so3_idx\"] = 0.\n",
    "time_dict[\"so3_l_img_comp\"] = 0.\n",
    "time_dict[\"so3_l_real_comp\"] = 0.\n",
    "time_dict[\"so3_s_img_comp\"] = 0.\n",
    "time_dict[\"so3_s_real_comp\"] = 0.\n",
    "time_dict[\"se3_exp\"] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand((200, 1, 6), device=device)\n",
    "steps = 100\n",
    "for s in range(steps):\n",
    "    start = time.perf_counter()\n",
    "    exp = se3_Exp.apply(v)\n",
    "    end = time.perf_counter()\n",
    "    time_dict[\"se3_exp\"] += end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se3_exp:     0.0909 s\n",
      "\tso3_jl:     0.0471 s\n",
      "\t\tvec2skew:     0.0005 s\n",
      "\t\ttheta:     0.0001 s\n",
      "\t\tI:     0.0001 s\n",
      "\t\tIdx:     0.0001 s\n",
      "\t\tcoef1:     0.0193 s\n",
      "\t\t\tcoef1 zeros:     0.0001 s\n",
      "\t\t\tcoef1 large transform cos:     0.0033 s\n",
      "\t\t\tcoef1 large transform div:     0.0078 s\n",
      "\t\t\tcoef1 small transform:     0.0081 s\n",
      "\t\tcoef2:     0.0265 s\n",
      "\t\t\tcoef2 zeros:     0.0001 s\n",
      "\t\t\tcoef2 large transform:     0.0187 s\n",
      "\t\t\tcoef2 small transform:     0.0077 s\n",
      "\t\tres:     0.0003 s\n",
      "\tt:     0.0001 s\n",
      "\tso3_Exp:     0.0432 s\n",
      "\t\tso3_theta:     0.0001 s\n",
      "\t\tso3_placeholder:     0.0001 s\n",
      "\t\tso3_idx:     0.0001 s\n",
      "\t\tso3_l_img_comp:     0.0109 s\n",
      "\t\tso3_l_real_comp:     0.0081 s\n",
      "\t\tso3_s_img_comp:     0.0116 s\n",
      "\t\tso3_s_real_comp:     0.0116 s\n"
     ]
    }
   ],
   "source": [
    "print(\"se3_exp: {:10.4f} s\".format(time_dict[\"se3_exp\"]/steps))\n",
    "print(\"\\tso3_jl: {:10.4f} s\".format(time_dict[\"so3_jl\"]/steps))\n",
    "print(\"\\t\\tvec2skew: {:10.4f} s\".format(time_dict[\"vec2skew\"]/steps))\n",
    "print(\"\\t\\ttheta: {:10.4f} s\".format(time_dict[\"theta\"]/steps))\n",
    "print(\"\\t\\tI: {:10.4f} s\".format(time_dict[\"I\"]/steps))\n",
    "print(\"\\t\\tIdx: {:10.4f} s\".format(time_dict[\"idx\"]/steps))\n",
    "print(\"\\t\\tcoef1: {:10.4f} s\".format(time_dict[\"coef1\"]/steps))\n",
    "print(\"\\t\\t\\tcoef1 zeros: {:10.4f} s\".format(time_dict[\"coef1_z\"]/steps))\n",
    "print(\"\\t\\t\\tcoef1 large transform cos: {:10.4f} s\".format(time_dict[\"coef1_l_cos\"]/steps))\n",
    "print(\"\\t\\t\\tcoef1 large transform div: {:10.4f} s\".format(time_dict[\"coef1_l_div\"]/steps))\n",
    "print(\"\\t\\t\\tcoef1 small transform: {:10.4f} s\".format(time_dict[\"coef1_s_comp\"]/steps))\n",
    "print(\"\\t\\tcoef2: {:10.4f} s\".format(time_dict[\"coef2\"]/steps))\n",
    "print(\"\\t\\t\\tcoef2 zeros: {:10.4f} s\".format(time_dict[\"coef2_z\"]/steps))\n",
    "print(\"\\t\\t\\tcoef2 large transform: {:10.4f} s\".format(time_dict[\"coef2_l_comp\"]/steps))\n",
    "print(\"\\t\\t\\tcoef2 small transform: {:10.4f} s\".format(time_dict[\"coef2_s_comp\"]/steps))\n",
    "print(\"\\t\\tres: {:10.4f} s\".format(time_dict[\"res\"]/steps))\n",
    "print(\"\\tt: {:10.4f} s\".format(time_dict[\"t\"]/steps))\n",
    "print(\"\\tso3_Exp: {:10.4f} s\".format(time_dict[\"so3_Exp\"]/steps))\n",
    "print(\"\\t\\tso3_theta: {:10.4f} s\".format(time_dict[\"so3_theta\"]/steps))\n",
    "print(\"\\t\\tso3_placeholder: {:10.4f} s\".format(time_dict[\"theta\"]/steps))\n",
    "print(\"\\t\\tso3_idx: {:10.4f} s\".format(time_dict[\"so3_idx\"]/steps))\n",
    "print(\"\\t\\tso3_l_img_comp: {:10.4f} s\".format(time_dict[\"so3_l_img_comp\"]/steps))\n",
    "print(\"\\t\\tso3_l_real_comp: {:10.4f} s\".format(time_dict[\"so3_l_real_comp\"]/steps))\n",
    "print(\"\\t\\tso3_s_img_comp: {:10.4f} s\".format(time_dict[\"so3_s_img_comp\"]/steps))\n",
    "print(\"\\t\\tso3_s_real_comp: {:10.4f} s\".format(time_dict[\"so3_s_real_comp\"]/steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-03 11:19:07 7149:7149 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-05-03 11:19:07 7149:7149 ActivityProfilerController.cpp:300] Completed Stage: Collection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Source Location                                                              \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "                                                se3_Exp        22.20%       2.146ms        99.39%       9.606ms       9.606ms       0.000us         0.00%     481.000us     481.000us           0 b           0 b       5.50 Kb     -89.00 Kb             1  <built-in method apply of FunctionMeta object at 0x1001df0b0>                \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/3986874915.py(7): <module>                               \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3373): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3194): run_cell_async                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                        cudaMemcpyAsync        12.00%       1.160ms        12.00%       1.160ms      96.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            12  /tmp/ipykernel_7149/403853362.py(9): so3_Jl                                  \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/403853362.py(90): forward                                \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0x1001df0b0>                \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/3986874915.py(7): <module>                               \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                                so3_Exp         9.72%     939.000us        29.50%       2.851ms       2.851ms       0.000us         0.00%     198.000us     198.000us           0 b         -16 b       3.50 Kb     -18.00 Kb             1  <built-in method apply of FunctionMeta object at 0x1001df0b0>                \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/403853362.py(90): forward                                \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0x1001df0b0>                \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/3986874915.py(7): <module>                               \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         5.69%     550.000us         5.69%     550.000us     550.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  <built-in method zeros of type object at 0x7f8eadfdb9c0>                     \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/403853362.py(1): vec2skew                                \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/403853362.py(9): so3_Jl                                  \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/403853362.py(90): forward                                \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0x1001df0b0>                \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::nonzero         4.91%     475.000us        20.73%       2.004ms     167.000us     146.000us        30.35%     146.000us      12.167us           0 b           0 b      52.00 Kb           0 b            12  /tmp/ipykernel_7149/403853362.py(9): so3_Jl                                  \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/403853362.py(90): forward                                \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0x1001df0b0>                \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_7149/3986874915.py(7): <module>                               \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "Self CPU time total: 9.665ms\n",
      "Self CUDA time total: 481.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = state[..., :7]\n",
    "v = state[..., 7:]\n",
    "v = torch.rand((200, 1, 6), device=device)\n",
    "\n",
    "se3_Exp.apply(v)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"skew\"):\n",
    "        se3_Exp.apply(v)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  Source Location                                                              \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "                                        cudaMemcpyAsync        20.62%     936.000us        20.62%     936.000us      85.091us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            11  /tmp/ipykernel_28287/4015452305.py(76): forward                              \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0xf51d03a0>                 \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/3982759547.py(3): <module>                              \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3373): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                                so3_Exp        19.47%     884.000us        93.88%       4.262ms       4.262ms       0.000us         0.00%     196.000us     196.000us           0 b           0 b       3.50 Kb     -18.00 Kb             1  <built-in method apply of FunctionMeta object at 0xf51d03a0>                 \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/3982759547.py(3): <module>                              \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3373): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3194): run_cell_async                       \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                             aten::norm        13.90%     631.000us        21.21%     963.000us     963.000us       6.000us         3.06%       6.000us       6.000us           0 b           0 b       1.00 Kb       1.00 Kb             1  <built-in method norm of type object at 0x7f8db3cbc9c0>                      \n",
      "                                                                                                                                                                                                                                                             torch/functional.py(1379): norm                                              \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/4015452305.py(76): forward                              \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0xf51d03a0>                 \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/3982759547.py(3): <module>                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                          aten::nonzero         8.46%     384.000us        35.48%       1.611ms     146.455us     121.000us        61.73%     121.000us      11.000us           0 b           0 b      25.00 Kb       5.00 Kb            11  /tmp/ipykernel_28287/4015452305.py(76): forward                              \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0xf51d03a0>                 \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/3982759547.py(3): <module>                              \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3433): run_code                             \n",
      "                                                                                                                                                                                                                                                             IPython/core/interactiveshell.py(3373): run_ast_nodes                        \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "                                       cudaLaunchKernel         7.31%     332.000us         7.31%     332.000us     332.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  <built-in method norm of type object at 0x7f8db3cbc9c0>                      \n",
      "                                                                                                                                                                                                                                                             torch/functional.py(1379): norm                                              \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/4015452305.py(76): forward                              \n",
      "                                                                                                                                                                                                                                                             <built-in method apply of FunctionMeta object at 0xf51d03a0>                 \n",
      "                                                                                                                                                                                                                                                             /tmp/ipykernel_28287/3982759547.py(3): <module>                              \n",
      "                                                                                                                                                                                                                                                                                                                                          \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ---------------------------------------------------------------------------  \n",
      "Self CPU time total: 4.540ms\n",
      "Self CUDA time total: 196.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-02 11:36:11 28287:28287 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-05-02 11:36:11 28287:28287 ActivityProfilerController.cpp:300] Completed Stage: Collection\n"
     ]
    }
   ],
   "source": [
    "v = torch.rand((200, 1, 3), device=device)\n",
    "\n",
    "with profile(with_stack=True, profile_memory=True, use_cuda=True) as prof:\n",
    "    with record_function(\"skew\"):\n",
    "        so3_Exp.apply(v)\n",
    "\n",
    "print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_time_total\", row_limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
